---
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width=6, fig.asp = 0.618, collapse=TRUE) 
```

### Unit 3: Penguins
#### Lesson 5: Linear models
#### New functions: lm(), geom_smooth(), geom_ribbon(), plot.lm(), coef(), anova(), broom::tidy(), predict(), ggPredict(), expand.grid()         (AIC(), step(), ...?)

***

### Linear regression

Linear regression is one of the most commonly-used and easy-to-understand approaches to modeling. Linear regression involves a numerical outcome variable y and explanatory variable(s) x that are either numerical or categorical. We will start with simple (univariate) linear regression where y is modeled as a function of a single x variable.

The mathematical equation for simple regression is as follows:
$$y = \beta_1 + \beta_2*x + \varepsilon$$
where $\beta_1$ is the y-intercept, $\beta_2$ is the slope and $\varepsilon$ is the error term, or the portion of y that the regression model can't explain. 

### Model assumptions

Linear regression has 5 key assumptions:

-  Linear relationship 
-  Multivariate normality
-  No or little multicollinearity
-  No auto-correlation (samples are independent)
-  Homoscedasticity (variance is equal along the regression line)

Additionally, a good sample size rule of thumb is that the regression analysis requires at least 20 cases per independent variable in the analysis.

Here are some plots you want to look at before building a linear regression model:

-  Scatter plot: Visualise the linear relationship between the predictor and response, check for auto-correlation (if needed) and heteroscedasticity
-  Box plot: To spot any outlier observations in the variable. Having outliers in your predictor can drastically affect the predictions as they can affect the direction/slope of the line of best fit.
-  Histogram / density plot: To see the distribution of the predictor variable. Ideally, a close to normal distribution (a bell shaped curve), without being skewed to the left or right is preferred.
-  Q-Q plot: Also good for checking normality of your predictor variable
-  Correlation matrix (like `GGally::ggpairs()`) to check for multicollinearity in your explanatory variables

If you do encounter some problems with your data, there are many solutions that can help make linear regression an appropriate analysis. For example, if your explanatory variables aren't normal or you have heterscedasticity, a nonlinear transformation (such as $log(x)$, $x^2$ or $\sqrt{x}$) may solve the issue. If you have some nasty outliers, think about whether you might be (scientifically) justified in removing them from the dataset. If you several of your explanatory variables are correlated, you can remove some of them using stepwise regression. These will be covered in detail in a statistics class.

### Simple linear regression

Let's use the `palmerpenguins` data to look again at the relationship between bill length and bill depth. I'll do a little exploratory data analysis by viewing the first few data points and calculating summary statistics, then I'll look at the density plots and correlation with `GGally::ggpairs()`

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(palmerpenguins)
library(GGally) # ggPairs()
library(ggiraph)
library(ggiraphExtra) # ggPredict()
library(broom)  # tidy() augment()

# Exploratory data analysis:
glimpse(penguins)
summarize(penguins)
penguins %>% 
  select(bill_depth_mm, bill_length_mm) %>%
  GGally::ggpairs()  # calling out the library can avoid ambiguity for common-named functions, or just serve as a reminder to you
```

The linearity of the explanatory variable `bill_depth_mm` and the independent variable `bill_depth_mm` doesn't look very promising to me. Let's see what happens if we actually build the linear regression. We'll use the function `lm()` which stands for "linear model" and we'll indicate the relationship we want to test by putting a formula of the format `y~x` as a parameter. We'll save the model results in a variable, then use the `summary()` function to display the model results: 

```{r}
lm_1 = lm(bill_depth_mm ~ bill_length_mm, data=penguins)
summary(lm_1)
```

Both coefficients $\beta_1$ (the y-intercept) and $\beta_2$ (the slope associated with bill length) are statistically significant with $p<0.05$. However, the R-squared = 0.05, which means that bill length only explains about 5% of the variance in the bill depth observations. That's pretty pathetic. Since this is just a simple univariate regression model we can quickly plot the data and the linear model using `geom_smooth()` with `method="lm"` in `ggplot.` 

```{r}
ggplot(data=penguins, aes(x = bill_length_mm, y = bill_depth_mm)) +
     geom_point() +
     geom_smooth(method = "lm")
```

There are clear clusters in the data that are being ignored by our regression model, and the line doesn't seem to capture any interesting trend. The negative coefficient for bill_length_mm (as well as the plotted model) indicates that as bill length increases, bill depth decreases. That doesn't really make sense, right? What did we do wrong?

Well, grouping all of the penguin data, i.e. all three species, is pretty illogical. In fact, it violates another, less cited, assumption of linear regression: "All necessary independent variables are included in the regression that are specified by existing theory and/or research." We probably should have included species, or separated our analysis out into three separate models, one for each species. 

To check some of the assumptions of your linear model *post hoc*, you can send your saved model to the plot() function in base R:

```{r}
class(lm_1) # Note that your model output is a variable of the class "lm"
plot(lm_1)  # This actually calls plot.lm() since the first parameter is class "lm"
```

You can learn more about this quick-and-dirty diagnostics plotting trick by looking up the help page `?plot.lm`. The function `plot.lm()` is the version of the `plot()` function that is called when the parameter that you pass `plot()` is of the class "lm". This output provides you four useful plots:

-  Residuals vs Fitted Values, to check constant variance in residuals and linearity of association between predictors and outcome (look for a relatively straight line and random-looking scatterplot). By default, the 3 points with the highest residuals are labeled (i.e. the row number is printed on the figure).
-  Normal Q-Q Plot, to check the assumption of normally distributed residuals.
-  Root of Standardized residuals vs Fitted values, this is very similar to number 1, where the Y axis of residuals is in a different metric.
-  Residuals vs Leverage, to check if the leverage of certain observations are driving abnormal residual distributions, thus violating assumptions and biasing statistical tests. 

There are many objective statistical tests that can be performed to check the assumptions of your data. For more resources, look at the end of this tutorial page.

### Another simple linear model

Let's do the logical thing and test the same relationship `bill_depth_mm ~ bill_length_mm` but only looking at one species:

```{r}
gentoo = penguins %>% filter(species=="Gentoo")
lm_2 = lm(bill_depth_mm ~ bill_length_mm, data=gentoo)
summary(lm_2)
ggplot(data=gentoo, aes(x = bill_length_mm, y = bill_depth_mm)) +
     geom_point() +
     geom_smooth(method = "lm")
```

This trend looks a little better to me. The R-squared = 0.41, so the model explains about 41% of the variation. That's pretty impressive considering we only have one variable in there. Also, the model passes the sanity check because it seems logical that bill depth will increase with increasing bill length. 

We can actually use geom_smooth() to examine separate linear models for each of the three penguin species at once without formally running the regression:

```{r}
ggplot(data=penguins, aes(x=bill_length_mm, y=bill_depth_mm, color=species)) +
     geom_point() +
     geom_smooth(method = "lm")
```

So that makes it very clear that running all three species together was a serious logical error, and it produced a completely untrue result that bill depth increases as bill length decreases In fact, when we split the three species apart, we can see that bill depth increases with increasing bill length (as you'd expect) and the relationships look pretty similar for each species. This is an example of Simpson's paradox, which occurs when trends that appear when a dataset is separated into groups reverse when the data are aggregated. Basically, when doing statistics, you want to use your brain and your gut to build models that make sense.

### Multiple linear regression

In life, we typically can't do a very good job explaining variation in some dependent variable using just a single independent variable. Multiple linear regression is when we build a function with multiple independent variables of the form:

$$y = \beta_0 + \beta_1*x_1 + \beta_2*x_2 + ... + \varepsilon$$

When conducting multiple linear regression, all of the same assumptions and diagnostics apply, with one important addition: the interpretation of the associated effect of any one explanatory variable must be made in conjunction with the other explanatory variables included in your model.

#### A note on model goals:

The statistical decisions you make should account for your end goals. These are the two types of goals when building a model:

1. *Modeling for explanation:* When you want to explicitly describe and quantify the relationship between the outcome variable y and a set of explanatory variables x, determine the significance of any relationships, have measures summarizing these relationships, and possibly identify any causal relationships between the variables.
2. *Modeling for prediction:* When you want to predict an outcome variable  y based on the information contained in a set of predictor variables x. Unlike modeling for explanation, however, you don’t care so much about understanding how all the variables relate and interact with one another, but rather only whether you can make good predictions about y using the information in x.

In this lesson, and in general when you are trying to "play it safe" in your analyses, you will be modeling for explanation. This means if you are modeling some $y$ as a a function of $x_1$ and $x_2$, but $x_1$ and $x_2$ are quite collinear, then you won't be able to differentiate the unique impact of either $x$ variable on $y$ because, for example, $x_1$ may be stealing some of the variation from $x_2$. Then the total impact of $x_2$ on $y$ will be unfairly biased small, and the impact of $x_1$ will be unfairly biased large. Who knows what chaos will ensue when you use these biased models to guide science, policy, etc.?

However, if you are modeling for prediction, and don't actually care what the relative impact of $x_1$ or $x_2$ is on $y$, but you want your $y$ predictions to be as accurate and precise as possible, then you don't have to worry about multicollinearity. For example, weather predictions are like this. Meteorologists just throw everything they can into their models, even though their "explanatory variables" can be highly correlated, becuase they aren't trying to demonstrate a relationship between rainfall and pressure, they are just trying to let you know whether it'll be a good weekend for a beach trip.

#### Continuous vs. categorical variables:

-  Continuous variable: numeric variables that can have an infinite number of values between any two values. Example: `bill_depth_mm`, `bill_length_mm`
-  Categorical varialbe: (a.k.a. discrete or nominal variables) contain a finite number of categories or distinct groups. Example: `species`. These should typically be in the `factor` class in R.

There are cases when you, the data scientist, can make a conscientious choice between assigning a variable as continuous vs. categorical. A good example is "year". If you are looking for a trend in your data over time, year should be treated as a continuous variable. If you are trying to account for some wacky conditions that can change from year to year, but that probably don't consitute a temporal trend, you could treat year as a categorical variable.

#### One continuous and one categorical explanatory variable

Our adventures in simple regression taught us that we shouldn't model bill depth as a function of bill length without accounting for species. We built three separate models, one for each species. Another option is to build one model, but include species as an explanatory variable with the function.

This is very simple to implement in the `lm()` function. We'll try a function of the form `bill_depth_mm ~ bill_length_mm + species`. This model will estimate a single slope associated with bill length and a different intercept for each species. The resulting prediction will look like three parallel lines, one for each species. 

```{r}
# Drop NA data before fitting model. This helps me avoid problems down the line with predict()
penguins_lm_3 = penguins %>%
  filter(!is.na(bill_depth_mm),
         !is.na(bill_length_mm),
         !is.na(species))
lm_3 = lm(bill_depth_mm ~ bill_length_mm + species, data=penguins_lm_3)
```


There are several different ways to access your model results. You can copy and paste coefficient estimates, p-values, etc. from the `summary()` output, or you can extract various elements from the model variable using specialized functions like `coef()`. If you want your results to look like an ANOVA table (remember, ANOVA and linear regression are mathematically equivalent), you can use the `anova()` function. Probably the most efficient way to get at your model results makes use of the `tidy()` function in the `broom` package in the tidyverse. Note that `broom` is one of the packages that, although it is part of the tidyverse, it does not load up with the `library(tidyverse)`, it must be loaded separately with `library(broom)`. This outputs the model results in a neat data frame, which you can easily export to a `.csv` file to save or create a table in your manuscript. Check the help page `?tidy.lm` and you can see that you can ask for confidence intervals to be output on your coefficients.

```{r}
coef(lm_3)
anova(lm_3)
broom::tidy(lm_3)
broom::tidy(lm_3, conf.int = TRUE, conf.level = 0.95)
```

Now let's plot the data, the linear model predictions and the standard errors on those predictions. Although it seems super similar, recall that the plot we made at the end of our simple linear regression section actually had the results of three distinct linear models plotted onto the same figure: one for each speices. This multiple regression model `lm_3` that we created is a single model with two explanatory variables, bill_length_mm and species. The slopes associated with each species must be equivalent in this model formulation. 

The combined libraries ggiraph and ggiraphExtra have a really convenient plot function for examining a model called `ggPredict()`. You can set the parameters so that standard errors are printed around the model and you can also make the plot interactive. That means if you click on a point or a line, a box will pop up with information on that datapoint:

```{r}
library(ggiraph)
library(ggiraphExtra)
ggPredict(lm_3, se=TRUE, interactive=TRUE)
```

While `ggPredict()` is a fabulous function, there is not a lot of room to customize it. The more formal and more customizable method for accessing your model predictions is using the `predict()` function in base R. 

```{r}
lm_3_predictions = predict(lm_3, interval="confidence") # Calculates lm predictions for the original dataset
head(lm_3_predictions)
penguins_lm_3_predict = cbind(penguins_lm_3, lm_3_predictions)
ggplot(penguins_lm_3_predict, aes(x = bill_length_mm, y = bill_depth_mm, color = species) ) +
     geom_point() +
     geom_ribbon( aes(ymin = lwr, ymax = upr, fill = species, color = NULL), alpha = .1) +
     geom_line(aes(y = fit), size = 1) +
     theme_bw()
```


The fitted lines in all the plots so far are different lengths. This is because we have slightly different ranges of bill length data for each species category in the dataset. By default when using `predict()` we get the fitted values; i.e., the predicted values from the dataset used in model fitting.

I think having different line lengths is fine here, but there are times when we want to draw each line across the entire range of the variable in the dataset. Also, sometimes our data are so sparse that our fitted line ends up not being very smooth; this can be especially problematic for non-linear fits. In both of these situations we’d want to make a new dataset for making the predictions.

Let’s make group lines using the entire range of bill length instead of the within-species range. We can make a variable with the full range of bill length via seq(), making a sequence from the minimum to maximum dataset value. I use 0.1 as the increment in seq(); the increment value you’ll want to use depends on the range of your variable. Then to get the full range of bill length associated with each species category we can use `expand.grid()` in base R:

```{r}
# Build a new bill_length_mm dataset that spans the full range of the original data at even intervals
newdata_bill_length_mm = seq(min(penguins_lm_3$bill_length_mm), max(penguins_lm_3$bill_length_mm), by = .1)
# Repeat complete bill_length_mm data for each species
newdata = expand.grid(bill_length_mm = newdata_bill_length_mm, species = unique(penguins_lm_3$species) )
head(newdata)
```

The key to making a dataset for prediction is that it must have every variable used in the model in it. You will get an error if you forget a variable or make a typo in one of the variable names. Note that the prediction dataset does not need to contain the response variable.

We use this prediction dataset with the newdata argument in `predict()`. We can add the predicted values to the prediction dataset using `cbind()`. When we make the plot of the fitted lines now we can see that the line for each species covers the same range. There are now two datasets used in the plotting code: the original for the points and newdata for the predicted line and 95% confidence intervals"

```{r}
newdata_predict_lm_3 = cbind(newdata, predict(lm_3, interval="confidence", newdata = newdata))
dim(newdata_predict_lm_3)
ggplot() +
     geom_point(data=penguins_lm_3_predict, aes(x = bill_length_mm, y = bill_depth_mm, color = species)) +
     geom_ribbon(aes(ymin=lwr, ymax=upr, x = bill_length_mm, fill = species, color = NULL), alpha = .1, data=newdata_predict_lm_3) +
     geom_line(aes(y = fit, x = bill_length_mm, color=species), size = 1, data=newdata_predict_lm_3) +
     theme_bw()
```

Another way to generate model predictions is using the `augment()` function in the `broom` package. This function fits into the dplyr coding flow, so you call it with a pipe and the model estimate columns automatically append to the data that you are using. This avoids the extra call to `cbind()`, and perhaps a mistake in joining data frames.

```{r}
# Get model predictions
lm_3_predict = lm_3 %>%
  augment(penguins_lm_3, se_fit=TRUE) %>%
  mutate(lwr = .fitted - 1.96 * .se.fit, upr = .fitted + 1.96 * .se.fit) # Calculate 95% C.I. using SE
# Plot the data and the model predictions
ggplot(aes(x = bill_length_mm, y = bill_depth_mm, color = species), data=lm_3_predict) +
  geom_point() +
  geom_ribbon(aes(ymin = lwr, ymax = upr, fill = species, color = NULL), alpha = .15) +
  geom_line( aes(y = .fitted), size = 1)
```

Similarly, we can use `augment()` to generate predictions with new data, so that our predicted model plots extend beyond the range of the data used to fit the model. To stay within the tidyverse, we'll use `tidyr::expand()` in place of `expand.grid()` to generate all possible combinations of the explanatory variables used in our model.

```{r}
# Get model predictions with newdata
newdata = penguins_lm_3 %>% expand(bill_length_mm, species)
lm_3_predict = lm_3 %>%
  augment(newdat = newdata, se_fit=TRUE) %>%
  mutate(lwr = .fitted - 1.96 * .se.fit, upr = .fitted + 1.96 * .se.fit) # Calculate 95% C.I. using SE
# Plot the data and the model predictions
ggplot() +
  geom_point(aes(x = bill_length_mm, y = bill_depth_mm, color = species), data=penguins_lm_3) +
  geom_ribbon(aes(ymin = lwr, ymax = upr, x = bill_length_mm, fill = species, color = NULL), alpha = .15, data=lm_3_predict) +
  geom_line(data=lm_3_predict, aes(y = .fitted, x = bill_length_mm, color=species), size = 1)
```

Why am I showing you two completely different ways to generate the same predictions and the same plot? Well, that's the secret of programming. There is always more than one way to get something done. By trying out the different methods to accomplish the same task, you'll become a more versatile and efficient programmer. For your own linear models, use the prediction method that makes the most sense for you. However, one benefit of the tidyverse method is that if you wind up running statistical analyses on Big Data and need to build many similar models, these methods combined with tools in the tidyverse `purrr` package make this very easy and efficient to code.

I'm proud of that last plot so I'm going to make it a bit prettier and save it:

```{r}
ggplot() +
  geom_point(aes(x = bill_length_mm, y = bill_depth_mm, color = species), data=penguins_lm_3) +
  geom_ribbon(aes(ymin = lwr, ymax = upr, x = bill_length_mm, fill = species, color = NULL), alpha = .15, data=lm_3_predict) +
  geom_line(data=lm_3_predict, aes(y = .fitted, x = bill_length_mm, color=species), size = 1) +
  theme_bw() +
  xlab("Bill length (mm)") + ylab("Bill depth (mm)") +
  ggsave(filename = "figures/bill_depth_model.png", device = "png", width = 5, height = 3, units = "in", dpi = 300)
```




Including species:

```{r}

lm_4 = lm(bill_depth_mm ~ bill_length_mm*species, data=penguins)
AIC(lm_1, lm_3, lm_4)

# https://cran.r-project.org/web/packages/ggiraphExtra/vignettes/ggPredict.html
ggPredict(lm_4, se=TRUE, interactive=TRUE)
```

With predict():
https://aosmith.rbind.io/2018/11/16/plot-fitted-lines/
interval = confidence vs. interval = prediction

with ggPredict():
https://cran.r-project.org/web/packages/ggiraphExtra/vignettes/ggPredict.html


### More information

Overview of basic regression capabilities in R:
https://www.statmethods.net/stats/regression.html

Diagnostic tests for linear regression:
https://www.statmethods.net/stats/rdiagnostics.html
https://www.ianruginski.com/post/regressionassumptions/

If you are interested in Model-II regression (where there is error in the measurement of the independent variables as well as the dependent variables), the `lmodel2` package can run a variety of model 2 regressions, plot them, calculate confidence intervals, and perform statistical tests.

